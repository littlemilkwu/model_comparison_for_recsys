{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import getsizeof\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Numpy: 無法確定 index 就是 user, item's id\n",
    "Pandas: 計算時使用 numpy，資料結構依賴 Pandas\n",
    "</pre>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* filter: > 3 interactions\n",
    "* create matrix\n",
    "* train test split\n",
    "* train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_interaction(df_inter):\n",
    "    print('origin shape: ', df_inter.shape)\n",
    "    vc_user = df_inter['user_id'].value_counts()\n",
    "    mask = df_inter['user_id'].isin(vc_user[vc_user >= 3].index)\n",
    "    df_inter = df_inter.loc[mask].reset_index(drop=True)\n",
    "    print('> 3 interactions: ', df_inter.shape)\n",
    "    return df_inter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape:  (792062, 3)\n",
      "> 3 interactions:  (790197, 3)\n",
      "[13014 13015 13016 13017 13018 13019 13020 13021 13022 13023] , unique:  13024\n",
      "[22337 22338 22339 22340 22341 22342 22343 22344 22345 22346] , unique:  22347\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "一定得先取出 user, item 的 unique，再去切分 train test。\n",
    "'''\n",
    "\n",
    "df_inter = pd.read_csv(data_path_douban + 'user_book.dat', sep='\\t', header=None).rename({\n",
    "    0: 'user_id',\n",
    "    1: 'item_id',\n",
    "    2: 'rating',\n",
    "}, axis=1)\n",
    "\n",
    "# index - 1\n",
    "df_inter['user_id'], df_inter['item_id'] = df_inter['user_id'] - 1, df_inter['item_id'] - 1\n",
    "ls_user_unique = df_inter['user_id'].unique()\n",
    "ls_item_unique = df_inter['item_id'].unique()\n",
    "ls_user_unique.sort()\n",
    "ls_item_unique.sort()\n",
    "\n",
    "df_inter = filter_interaction(df_inter)\n",
    "print(ls_user_unique[-10:], ', unique: ', len(ls_user_unique))\n",
    "print(ls_item_unique[-10:], ', unique: ', len(ls_item_unique))\n",
    "\n",
    "df_train_inter, df_test_inter = train_test_split(df_inter, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "df_train_inter, df_test_inter = df_train_inter.reset_index(drop=True), df_test_inter.reset_index(drop=True)\n",
    "\n",
    "df_train_inter.to_csv(data_preprocessing + 'douban_train_interaction.csv', index=False)\n",
    "df_train_inter.to_csv(data_preprocessing + 'douban_test_interaction.csv', index=False)\n",
    "np.save(data_preprocessing + 'douban_user_unique', ls_user_unique)\n",
    "np.save(data_preprocessing + 'douban_item_unique', ls_item_unique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## movie_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape:  (100000, 4)\n",
      "> 3 interactions:  (100000, 4)\n",
      "[933 934 935 936 937 938 939 940 941 942] , unique:  943\n",
      "[1672 1673 1674 1675 1676 1677 1678 1679 1680 1681] , unique:  1682\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "一定得先取出 user, item 的 unique，再去切分 train test。\n",
    "'''\n",
    "\n",
    "df_inter = pd.read_csv(data_path_movie + 'user_movie.dat', sep='\\t', header=None).rename({\n",
    "    0: 'user_id',\n",
    "    1: 'item_id',\n",
    "    2: 'rating',\n",
    "}, axis=1)\n",
    "\n",
    "# index - 1\n",
    "df_inter['user_id'], df_inter['item_id'] = df_inter['user_id'] - 1, df_inter['item_id'] - 1\n",
    "ls_user_unique = df_inter['user_id'].unique()\n",
    "ls_item_unique = df_inter['item_id'].unique()\n",
    "ls_user_unique.sort()\n",
    "ls_item_unique.sort()\n",
    "\n",
    "df_inter = filter_interaction(df_inter)\n",
    "print(ls_user_unique[-10:], ', unique: ', len(ls_user_unique))\n",
    "print(ls_item_unique[-10:], ', unique: ', len(ls_item_unique))\n",
    "\n",
    "df_train_inter, df_test_inter = train_test_split(df_inter, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "df_train_inter, df_test_inter = df_train_inter.reset_index(drop=True), df_test_inter.reset_index(drop=True)\n",
    "\n",
    "df_train_inter.to_csv(data_preprocessing + 'movielen_train_interaction.csv', index=False)\n",
    "df_train_inter.to_csv(data_preprocessing + 'movielen_test_interaction.csv', index=False)\n",
    "np.save(data_preprocessing + 'movielen_user_unique', ls_user_unique)\n",
    "np.save(data_preprocessing + 'movielen_item_unique', ls_item_unique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape:  (198397, 3)\n",
      "> 3 interactions:  (188456, 3)\n",
      "[16229 16230 16231 16232 16233 16234 16235 16236 16237 16238] , unique:  16239\n",
      "[14274 14275 14276 14277 14278 14279 14280 14281 14282 14283] , unique:  14284\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "一定得先取出 user, item 的 unique，再去切分 train test。\n",
    "'''\n",
    "\n",
    "df_inter = pd.read_csv(data_path_yelp + 'user_business.dat', sep='\\t', header=None).rename({\n",
    "    0: 'user_id',\n",
    "    1: 'item_id',\n",
    "    2: 'rating',\n",
    "}, axis=1)\n",
    "\n",
    "# index - 1\n",
    "df_inter['user_id'], df_inter['item_id'] = df_inter['user_id'] - 1, df_inter['item_id'] - 1\n",
    "ls_user_unique = df_inter['user_id'].unique()\n",
    "ls_item_unique = df_inter['item_id'].unique()\n",
    "ls_user_unique.sort()\n",
    "ls_item_unique.sort()\n",
    "\n",
    "df_inter = filter_interaction(df_inter)\n",
    "print(ls_user_unique[-10:], ', unique: ', len(ls_user_unique))\n",
    "print(ls_item_unique[-10:], ', unique: ', len(ls_item_unique))\n",
    "\n",
    "df_train_inter, df_test_inter = train_test_split(df_inter, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "df_train_inter, df_test_inter = df_train_inter.reset_index(drop=True), df_test_inter.reset_index(drop=True)\n",
    "\n",
    "df_train_inter.to_csv(data_preprocessing + 'yelp_train_interaction.csv', index=False)\n",
    "df_train_inter.to_csv(data_preprocessing + 'yelp_test_interaction.csv', index=False)\n",
    "np.save(data_preprocessing + 'yelp_user_unique', ls_user_unique)\n",
    "np.save(data_preprocessing + 'yelp_item_unique', ls_item_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
