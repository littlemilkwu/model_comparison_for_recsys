{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from surprise import accuracy, Dataset, Reader, KNNWithMeans, NMF\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from collections import defaultdict\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kf = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_douban_inter = pd.read_csv(data_preprocessing + 'douban_inter.csv', dtype={\n",
    "    'user_id': str,\n",
    "    'item_id': str,\n",
    "})\n",
    "\n",
    "df_movie_inter = pd.read_csv(data_preprocessing + 'movie_inter.csv', dtype={\n",
    "    'user_id': str,\n",
    "    'item_id': str,\n",
    "\n",
    "})\n",
    "df_yelp_inter = pd.read_csv(data_preprocessing + 'yelp_inter.csv', dtype={\n",
    "    'user_id': str,\n",
    "    'item_id': str,\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering & MF\n",
    "* [Surprise Basic Usage](https://surprise.readthedocs.io/en/stable/getting_started.html)\n",
    "* [Surprise Prediction Algorithms List](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)\n",
    "* [Surprise Similarity Options](https://surprise.readthedocs.io/en/stable/prediction_algorithms.html)\n",
    "* [Surprise Accuracy RMSE](https://surprise.readthedocs.io/en/stable/accuracy.html)\n",
    "* [Surprise Recall](https://surprise.readthedocs.io/en/stable/FAQ.html)\n",
    "* [NDGC 計算方式](https://ithelp.ithome.com.tw/articles/10299050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cf_mf():\n",
    "    algo_UCF_s = KNNWithMeans(sim_options={\n",
    "        \"name\": \"cosine\",\n",
    "        \"user_based\": True\n",
    "    })\n",
    "    algo_UCF_p = KNNWithMeans(sim_options={\n",
    "        \"name\": \"pearson_baseline\",\n",
    "        \"user_based\": True,\n",
    "        'shrinkage': 0\n",
    "    })\n",
    "\n",
    "    algo_ICF_s = KNNWithMeans(sim_options={\n",
    "        \"name\": \"cosine\",\n",
    "        \"user_based\": False\n",
    "    })\n",
    "\n",
    "    algo_ICF_p = KNNWithMeans(sim_options={\n",
    "        \"name\": \"pearson_baseline\",\n",
    "        \"user_based\": False,\n",
    "        'shrinkage': 0\n",
    "    })\n",
    "    algo_NMF = NMF()\n",
    "    return algo_UCF_s, algo_UCF_p, algo_ICF_s, algo_ICF_p, algo_NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cf_eval_metrics(predictions, k=10, threshold=3.5):\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    ls_recall = []\n",
    "    ls_ndcg = []\n",
    "    \n",
    "    dict_user_ratings = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        dict_user_ratings[uid].append((est, true_r))\n",
    "\n",
    "    for uid, ratings in dict_user_ratings.items():\n",
    "        ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        true_ratings = sorted(ratings, key=lambda x: x[1], reverse=True)\n",
    "        # recall\n",
    "        num_rel = sum(1 for (est, true_r) in ratings if true_r > threshold)\n",
    "        num_rel_top_k = sum(1 for (est, true_r) in ratings[:k] if true_r > threshold and est > threshold)\n",
    "        recall = num_rel_top_k / num_rel if num_rel != 0 else 0\n",
    "        ls_recall.append(recall)\n",
    "\n",
    "        # ndcg\n",
    "        dcg = sum(true_r / math.log(i + 2, 2) for i, (est, true_r) in enumerate(ratings[:k]))\n",
    "        idcg = sum(true_r / math.log(i + 2, 2) for i, (est, true_r) in enumerate(true_ratings[:k]))\n",
    "        ndcg = dcg / idcg\n",
    "        ls_ndcg.append(ndcg)\n",
    "\n",
    "    mean_recall = sum(ls_recall) / len(ls_recall)\n",
    "    mean_ndcg = sum(ls_ndcg) / len(ls_ndcg)\n",
    "    \n",
    "    return [rmse, mean_recall, mean_ndcg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 fold => 3m 13.4s\n",
    "def calc_all_cf_model(df_inter, data_name):\n",
    "    ls_result = []\n",
    "    for i, (train_idx, test_idx) in enumerate(Kf.split(df_inter)):\n",
    "        print(f'\\n***** Fold {i} *****')\n",
    "        algo_UCF_s, algo_UCF_p, algo_ICF_s, algo_ICF_p, algo_NMF = init_cf_mf()\n",
    "        \n",
    "        df_train = df_inter.iloc[train_idx]\n",
    "        df_test = df_inter.iloc[test_idx]\n",
    "\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        train_set = Dataset.load_from_df(df_train[['user_id', 'item_id', 'rating']], reader=reader)\n",
    "        train_set = train_set.build_full_trainset()\n",
    "\n",
    "        algo_UCF_s.fit(train_set)\n",
    "        algo_UCF_p.fit(train_set)\n",
    "        algo_ICF_s.fit(train_set)\n",
    "        algo_ICF_p.fit(train_set)\n",
    "        algo_NMF.fit(train_set)\n",
    "\n",
    "        pred_UCF_s = algo_UCF_s.test(df_test.values)\n",
    "        pred_UCF_p = algo_UCF_p.test(df_test.values)\n",
    "        pred_ICF_s = algo_ICF_s.test(df_test.values)\n",
    "        pred_ICF_p = algo_ICF_p.test(df_test.values)\n",
    "        pred_NMF = algo_NMF.test(df_test.values)\n",
    "\n",
    "        metrics_UCF_s = ['UCF_s', i, data_name] + calc_cf_eval_metrics(pred_UCF_s)\n",
    "        metrics_UCF_p = ['UCF_p', i, data_name] + calc_cf_eval_metrics(pred_UCF_p)\n",
    "        metrics_ICF_s = ['ICF_s', i, data_name] + calc_cf_eval_metrics(pred_ICF_s)\n",
    "        metrics_ICF_p = ['ICF_p', i, data_name] + calc_cf_eval_metrics(pred_ICF_p)\n",
    "        metrics_NMF = ['NMF', i, data_name] + calc_cf_eval_metrics(pred_NMF)\n",
    "\n",
    "        ls_result.extend([metrics_UCF_s, metrics_UCF_p, metrics_ICF_s, metrics_ICF_p, metrics_NMF])\n",
    "    return ls_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Fold 0 *****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/littlemilk/MLG/HW3/model_compare.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ls_result \u001b[39m=\u001b[39m calc_all_cf_model(df_douban_inter, \u001b[39m'\u001b[39;49m\u001b[39mdouban\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m all_result\u001b[39m.\u001b[39mextend(ls_result)\n",
      "\u001b[1;32m/home/littlemilk/MLG/HW3/model_compare.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m df_test \u001b[39m=\u001b[39m df_inter\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m reader \u001b[39m=\u001b[39m Reader(rating_scale\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m train_set \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mload_from_df(df_train[[\u001b[39m'\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mitem_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m]], reader\u001b[39m=\u001b[39;49mreader)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m train_set \u001b[39m=\u001b[39m train_set\u001b[39m.\u001b[39mbuild_full_trainset()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnetai_940_2_littlemilk/home/littlemilk/MLG/HW3/model_compare.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m algo_UCF_s\u001b[39m.\u001b[39mfit(train_set)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/surprise/dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[0;34m(cls, df, reader)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_df\u001b[39m(\u001b[39mcls\u001b[39m, df, reader):\n\u001b[1;32m    152\u001b[0m     \u001b[39m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[39m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m            specified.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m DatasetAutoFolds(reader\u001b[39m=\u001b[39;49mreader, df\u001b[39m=\u001b[39;49mdf)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/surprise/dataset.py:262\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[0;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39melif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m df\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_ratings \u001b[39m=\u001b[39m [\n\u001b[1;32m    263\u001b[0m         (uid, iid, \u001b[39mfloat\u001b[39m(r), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[39mfor\u001b[39;00m (uid, iid, r) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust specify ratings file or dataframe.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterhub/lib/python3.9/site-packages/surprise/dataset.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39melif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m df\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_ratings \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 263\u001b[0m         (uid, iid, \u001b[39mfloat\u001b[39m(r), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[39mfor\u001b[39;00m (uid, iid, r) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust specify ratings file or dataframe.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ls_result = calc_all_cf_model(df_douban_inter, 'douban')\n",
    "all_result.extend(ls_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Fold 0 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9587\n",
      "RMSE: 0.9543\n",
      "RMSE: 0.9469\n",
      "RMSE: 0.9440\n",
      "RMSE: 0.9674\n",
      "\n",
      "***** Fold 1 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9554\n",
      "RMSE: 0.9488\n",
      "RMSE: 0.9441\n",
      "RMSE: 0.9427\n",
      "RMSE: 0.9628\n",
      "\n",
      "***** Fold 2 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9537\n",
      "RMSE: 0.9500\n",
      "RMSE: 0.9386\n",
      "RMSE: 0.9369\n",
      "RMSE: 0.9637\n",
      "\n",
      "***** Fold 3 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9547\n",
      "RMSE: 0.9490\n",
      "RMSE: 0.9445\n",
      "RMSE: 0.9421\n",
      "RMSE: 0.9651\n",
      "\n",
      "***** Fold 4 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9593\n",
      "RMSE: 0.9550\n",
      "RMSE: 0.9472\n",
      "RMSE: 0.9446\n",
      "RMSE: 0.9670\n"
     ]
    }
   ],
   "source": [
    "ls_result = calc_all_cf_model(df_movie_inter, 'movie_len')\n",
    "all_result.extend(ls_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Fold 0 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0823\n",
      "RMSE: 1.1398\n",
      "RMSE: 1.0850\n",
      "RMSE: 1.1391\n",
      "RMSE: 1.1286\n",
      "\n",
      "***** Fold 1 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0746\n",
      "RMSE: 1.1275\n",
      "RMSE: 1.0826\n",
      "RMSE: 1.1390\n",
      "RMSE: 1.1301\n",
      "\n",
      "***** Fold 2 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0872\n",
      "RMSE: 1.1412\n",
      "RMSE: 1.0858\n",
      "RMSE: 1.1396\n",
      "RMSE: 1.1354\n",
      "\n",
      "***** Fold 3 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0821\n",
      "RMSE: 1.1309\n",
      "RMSE: 1.0842\n",
      "RMSE: 1.1378\n",
      "RMSE: 1.1339\n",
      "\n",
      "***** Fold 4 *****\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0851\n",
      "RMSE: 1.1363\n",
      "RMSE: 1.0844\n",
      "RMSE: 1.1380\n",
      "RMSE: 1.1337\n"
     ]
    }
   ],
   "source": [
    "ls_result = calc_all_cf_model(df_yelp_inter, 'yelp')\n",
    "all_result.extend(ls_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_result, columns=['model', 'kfold', 'data', 'RMSE', 'Recall', 'NDCG']).to_csv('output/CF_MF_result.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Machine & BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10855</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>2426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453</td>\n",
       "      <td>1263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11665</td>\n",
       "      <td>7717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790192</th>\n",
       "      <td>12832</td>\n",
       "      <td>2650</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790193</th>\n",
       "      <td>7823</td>\n",
       "      <td>3050</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790194</th>\n",
       "      <td>9347</td>\n",
       "      <td>18017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790195</th>\n",
       "      <td>10942</td>\n",
       "      <td>1443</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790196</th>\n",
       "      <td>5165</td>\n",
       "      <td>772</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id item_id  rating\n",
       "0        10855     938       4\n",
       "1        10027       3       3\n",
       "2          741    2426       5\n",
       "3          453    1263       4\n",
       "4        11665    7717       5\n",
       "...        ...     ...     ...\n",
       "790192   12832    2650       5\n",
       "790193    7823    3050       4\n",
       "790194    9347   18017       5\n",
       "790195   10942    1443       4\n",
       "790196    5165     772       3\n",
       "\n",
       "[790197 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_douban_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
